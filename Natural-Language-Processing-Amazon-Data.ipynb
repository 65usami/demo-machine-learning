{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     neg: loaded 700 reviews.\n",
      "     pos: loaded 700 reviews.\n"
     ]
    }
   ],
   "source": [
    "# 前処理: Train data\n",
    "datapath = Path('data/Amazon_review/Training_data')\n",
    "review_pattern = re.compile(r'cv\\d+')  # ファイル名が \"cv数字\"　で始まるファイル名かを調べる正規表現\n",
    "test_size = 0.25\n",
    "\n",
    "data_orig  = dict(neg=[], pos=[])\n",
    "data_train = dict(neg=[], pos=[])\n",
    "data_verify  = dict(neg=[], pos=[])\n",
    "\n",
    "np.random.seed(539167)\n",
    "\n",
    "for cls, reviews in data_orig.items():\n",
    "    for path in (datapath / cls).iterdir():\n",
    "        if review_pattern.match(path.name):\n",
    "            with open(path, 'r', encoding='latin') as src:\n",
    "                reviews.append(src.read())\n",
    "    print(f\"{cls:>8}: loaded {len(reviews)} reviews.\")\n",
    "    \n",
    "    data_train[cls], data_verify[cls] = train_test_split(reviews, test_size=test_size, random_state=539167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     neg: loaded 3 reviews(test_data).\n",
      "     pos: loaded 3 reviews(test_data).\n"
     ]
    }
   ],
   "source": [
    "# 前処理: Test data\n",
    "\n",
    "datapath_test = Path('data/Amazon_review/Test_data')\n",
    "review_test_pattern = re.compile(r'amazon_review_\\d+')\n",
    "data_test  = dict(neg=[], pos=[])\n",
    "\n",
    "for cls, reviews in data_test.items():\n",
    "    for path in (datapath_test / cls).iterdir():\n",
    "        if review_test_pattern.match(path.name):\n",
    "            with open(path, 'r', encoding='latin') as src:\n",
    "                reviews.append(src.read())\n",
    "    print(f\"{cls:>8}: loaded {len(reviews)} reviews(test_data).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 30989)\n"
     ]
    }
   ],
   "source": [
    "# 前処理: 特徴量作成\n",
    "\n",
    "def get_values_and_targets(data):\n",
    "    values = data['pos'] + data['neg']\n",
    "    target = [True]*len(data['pos']) + [False]*len(data['neg']) \n",
    "    target = np.array(target)\n",
    "    return values, target\n",
    "values_train, is_pos_train = get_values_and_targets(data_train)\n",
    "\n",
    "vocab = CountVectorizer(token_pattern=r'[a-zA-Z]{3,}')\n",
    "vocab.fit([data_orig['pos'][0]])\n",
    "features = vocab.fit_transform(values_train)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=3000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=539167, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter=3000, random_state=539167)\n",
    "model.fit(features, is_pos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/350 correct (81.143%)\n"
     ]
    }
   ],
   "source": [
    "# Train dataへの検証\n",
    "\n",
    "values_verify, is_pos_verify = get_values_and_targets(data_verify)\n",
    "pred_verify = model.predict(vocab.transform(values_verify))\n",
    "\n",
    "validation = (pred_verify == is_pos_verify)\n",
    "size    = validation.size\n",
    "correct = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos:   2/  3 correct (66.667%)\n",
      "neg:   1/  3 correct (33.333%)\n",
      "\n",
      "Total: 3/6 correct (50.000%)\n"
     ]
    }
   ],
   "source": [
    "# Test data検証\n",
    "\n",
    "values_test, is_pos_test = get_values_and_targets(data_test)\n",
    "pred_test = model.predict(vocab.transform(values_test))\n",
    "\n",
    "for cls in ('pos', 'neg'):\n",
    "    _values  = data_test[cls]\n",
    "    _is_pos = [(cls == 'pos')]*len(_values)\n",
    "    _pred    = model.predict(vocab.transform(_values))\n",
    "    _valid   = (_pred == _is_pos)\n",
    "    _size    = _valid.size\n",
    "    _correct = np.count_nonzero(_valid)\n",
    "    print(f\"{cls}: {_correct:>3d}/{_size:>3d} correct ({_correct*100/_size:.3f}%)\")\n",
    "\n",
    "print()\n",
    "validation = (pred_test == is_pos_test)\n",
    "size    = validation.size\n",
    "correct = np.count_nonzero(validation)\n",
    "print(f\"Total: {correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
